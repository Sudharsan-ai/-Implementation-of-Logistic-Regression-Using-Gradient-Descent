{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b02f0d-728d-416c-b0ba-e2c808d4fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Original Dataset ---\n",
      "\n",
      "   sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
      "0      1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
      "1      2      M  79.33  Central  78.33   Others   Science     77.48   \n",
      "2      3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
      "3      4      M  56.00  Central  52.00  Central   Science     52.00   \n",
      "4      5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
      "\n",
      "    degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
      "0   Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
      "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
      "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
      "3   Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
      "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  \n",
      "\n",
      "--- Step 2: Dataset Data Types ---\n",
      "\n",
      "gender            category\n",
      "ssc_p              float64\n",
      "ssc_b             category\n",
      "hsc_p              float64\n",
      "hsc_b             category\n",
      "hsc_s             category\n",
      "degree_p           float64\n",
      "degree_t          category\n",
      "workex            category\n",
      "etest_p            float64\n",
      "specialisation    category\n",
      "mba_p              float64\n",
      "status            category\n",
      "dtype: object\n",
      "\n",
      "--- Step 3: Encoded Dataset ---\n",
      "\n",
      "   gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  workex  \\\n",
      "0       1  67.00      1  91.00      1      1     58.00         2       0   \n",
      "1       1  79.33      0  78.33      1      2     77.48         2       1   \n",
      "2       1  65.00      0  68.00      0      0     64.00         0       0   \n",
      "3       1  56.00      0  52.00      0      2     52.00         2       0   \n",
      "4       1  85.80      0  73.60      0      1     73.30         0       0   \n",
      "\n",
      "   etest_p  specialisation  mba_p  status  \n",
      "0     55.0               1  58.80       1  \n",
      "1     86.5               0  66.28       1  \n",
      "2     75.0               0  57.80       1  \n",
      "3     66.0               1  59.43       0  \n",
      "4     96.8               0  55.50       1  \n",
      "\n",
      "--- Step 4: Target Variable (Y) ---\n",
      "\n",
      "[1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "\n",
      "--- Step 5: Predicted Values (y_pred) ---\n",
      "\n",
      "[1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1\n",
      " 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0]\n",
      "\n",
      "--- Step 6: Model Accuracy ---\n",
      "\n",
      "Accuracy: 0.8558139534883721\n",
      "\n",
      "--- Step 7: Actual Target Values (Y) ---\n",
      "\n",
      "[1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0\n",
      " 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "\n",
      "--- Step 8: Prediction for New Input 1 ---\n",
      "\n",
      "[1]\n",
      "\n",
      "--- Step 9: Prediction for New Input 2 ---\n",
      "\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Program to implement Logistic Regression Using Gradient Descent.\n",
    "Developed by: SUDHARSAN S\n",
    "RegisterNumber: 2122240403334\n",
    "\"\"\"\n",
    "\n",
    "# 1. Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2. Load the Dataset\n",
    "dataset = pd.read_csv(\"Placement_Data.csv\")\n",
    "print(\"\\n--- Step 1: Original Dataset ---\\n\")\n",
    "print(dataset.head())\n",
    "\n",
    "# 3. Drop Irrelevant Columns\n",
    "dataset = dataset.drop('sl_no', axis=1)\n",
    "dataset = dataset.drop('salary', axis=1)\n",
    "\n",
    "# 4. Convert Categorical Data to Category Type\n",
    "dataset[\"gender\"] = dataset[\"gender\"].astype('category')\n",
    "dataset[\"ssc_b\"] = dataset[\"ssc_b\"].astype('category')\n",
    "dataset[\"hsc_b\"] = dataset[\"hsc_b\"].astype('category')\n",
    "dataset[\"degree_t\"] = dataset[\"degree_t\"].astype('category')\n",
    "dataset[\"workex\"] = dataset[\"workex\"].astype('category')\n",
    "dataset[\"specialisation\"] = dataset[\"specialisation\"].astype('category')\n",
    "dataset[\"status\"] = dataset[\"status\"].astype('category')\n",
    "dataset[\"hsc_s\"] = dataset[\"hsc_s\"].astype('category')\n",
    "\n",
    "print(\"\\n--- Step 2: Dataset Data Types ---\\n\")\n",
    "print(dataset.dtypes)\n",
    "\n",
    "# 5. Encode Categorical Data into Numerical Codes\n",
    "dataset[\"gender\"] = dataset[\"gender\"].cat.codes\n",
    "dataset[\"ssc_b\"] = dataset[\"ssc_b\"].cat.codes\n",
    "dataset[\"hsc_b\"] = dataset[\"hsc_b\"].cat.codes\n",
    "dataset[\"degree_t\"] = dataset[\"degree_t\"].cat.codes\n",
    "dataset[\"workex\"] = dataset[\"workex\"].cat.codes\n",
    "dataset[\"specialisation\"] = dataset[\"specialisation\"].cat.codes\n",
    "dataset[\"status\"] = dataset[\"status\"].cat.codes\n",
    "dataset[\"hsc_s\"] = dataset[\"hsc_s\"].cat.codes\n",
    "\n",
    "print(\"\\n--- Step 3: Encoded Dataset ---\\n\")\n",
    "print(dataset.head())\n",
    "\n",
    "# 6. Define Features (X) and Target (Y)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:, -1].values\n",
    "\n",
    "print(\"\\n--- Step 4: Target Variable (Y) ---\\n\")\n",
    "print(Y)\n",
    "\n",
    "# 7. Initialize Parameters\n",
    "theta = np.random.randn(X.shape[1])\n",
    "y = Y\n",
    "\n",
    "# 8. Define Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 9. Define Loss Function\n",
    "def loss(theta, X, y):\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    return -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "# 10. Gradient Descent Function\n",
    "def gradient_descent(theta, X, y, alpha, num_iterations):\n",
    "    m = len(y)\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(X.dot(theta))\n",
    "        gradient = X.T.dot(h - y) / m\n",
    "        theta -= alpha * gradient\n",
    "    return theta\n",
    "\n",
    "# 11. Train the Model using Gradient Descent\n",
    "theta = gradient_descent(theta, X, y, alpha=0.01, num_iterations=1000)\n",
    "\n",
    "# 12. Prediction Function\n",
    "def predict(theta, X):\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    y_pred = np.where(h >= 0.5, 1, 0)\n",
    "    return y_pred\n",
    "\n",
    "# 13. Make Predictions on Training Data\n",
    "y_pred = predict(theta, X)\n",
    "\n",
    "print(\"\\n--- Step 5: Predicted Values (y_pred) ---\\n\")\n",
    "print(y_pred)\n",
    "\n",
    "# 14. Calculate Model Accuracy\n",
    "accuracy = np.mean(y_pred.flatten() == y)\n",
    "print(\"\\n--- Step 6: Model Accuracy ---\\n\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\n--- Step 7: Actual Target Values (Y) ---\\n\")\n",
    "print(Y)\n",
    "\n",
    "# 15. Test with New Data\n",
    "xnew = np.array([[0,87,0,95,0,2,78,2,0,0,1,0]])\n",
    "y_prednew = predict(theta, xnew)\n",
    "print(\"\\n--- Step 8: Prediction for New Input 1 ---\\n\")\n",
    "print(y_prednew)\n",
    "\n",
    "xnew = np.array([[0,0,0,0,0,2,8,2,0,0,1,0]])\n",
    "y_prednew = predict(theta, xnew)\n",
    "print(\"\\n--- Step 9: Prediction for New Input 2 ---\\n\")\n",
    "print(y_prednew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e2478-87a1-489b-ae99-8f11d5ee9a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
